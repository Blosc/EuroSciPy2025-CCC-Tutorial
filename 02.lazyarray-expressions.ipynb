{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Expressions containing NDArray objects\n",
    "\n",
    "Python-Blosc2 implements a powerful way to operate with NDArray arrays and other objects, called \"lazy expressions\".  A lazy expression is a lightweight object which stores a desired computation symbolically, with references to its operands (stored on disk or in memory), but does not execute until data is explicitly requested, e.g. if a slice of the computation result is requested. The lazy expression will then execute, but only on the necessary portion of the data, making it especially efficient, and avoiding large in-memory computations.\n",
    "\n",
    "In this tutorial, we will see how to do such lazy computations, which are especially useful when working with large arrays, owing to this avoidance of costly in-memory temporaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:50:50.172225Z",
     "start_time": "2025-08-04T11:50:49.854010Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import blosc2\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "%matplotlib ipympl\n",
    "\n",
    "# --- Memory profiler ---\n",
    "def getmem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1) A simple example\n",
    "First, let's create a couple of NDArray arrays. We're going to write them to disk since in principle we are interested in large arrays (so big that they can't fit in memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:50:50.305927Z",
     "start_time": "2025-08-04T11:50:50.182659Z"
    }
   },
   "outputs": [],
   "source": [
    "shape1 = (500, 10000)\n",
    "shape2 = (10, 500, 10000)\n",
    "a = blosc2.linspace(0, 1, np.prod(shape1), dtype=np.float32, shape=shape1, urlpath=\"a.b2nd\", mode=\"w\")\n",
    "b = blosc2.linspace(1, 2, np.prod(shape2), dtype=np.float64, shape=shape2, urlpath=\"b.b2nd\", mode=\"w\")\n",
    "\n",
    "# Now, let's create an expression that involves `a` and `b`, called `c`.\n",
    "c = a**2 + b**2 + 2 * a * b + 1\n",
    "print(c.info)  # at this stage, the expression has not been computed yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the type of `c` is a `LazyExpr` object.  This object is a placeholder for the actual computation that will be done when we compute the expression.  This is a very powerful feature because it allows us to build complex expressions without actually computing anything until we really need the result (or a portion of the result). \n",
    "\n",
    "**EXERCISE**: Moreover, we can access the individual metadata of the result (such as ``shape`` and `dtype`) ass sttributes of the lazy expression ``c`` rapidly, without computing anything. Time how long it takes (using the cell magic ``%time`` or line magic ``%%timeit``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:50:50.393958Z",
     "start_time": "2025-08-04T11:50:50.386111Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, note that the shapes of `a` and `b` are different. However, the shapes are compatible, and so Blosc2 applies **broadcasting** (à la NumPy) efficiently, both to obtain the precomputation metadata (very fast) as well as to perform the computation (slower). \n",
    "\n",
    "Now, let's see all this in action in computation. `LazyExpr` objects follow the [LazyArray interface](../../reference/lazyarray.html), and this provides several ways for performing the computation, depending on the object we want as the desired output.\n",
    "\n",
    "#### 1. Returning a NDArray array\n",
    "**i) Computing an expression** First, let's use the `compute` method. The result will be another NDArray array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:50:50.460942Z",
     "start_time": "2025-08-04T11:50:50.421027Z"
    }
   },
   "outputs": [],
   "source": [
    "m0 = getmem()\n",
    "t0 = time.time()\n",
    "d = c.compute()\n",
    "print(f\"Computation time {round((time.time() - t0)*1000,1)} ms\")\n",
    "print(f\"Memory used {round(getmem() - m0)} MB\")\n",
    "print(f\"Class: {type(d)}, occupies {round(d.schunk.cbytes / 1024 ** 2)} MB. Compression ratio {d.schunk.cratio:.2f}x\")\n",
    "del d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that just accessing metadata via e.g. ``c.shape`` took much less time, since it uses the metadata of the operands (plus broadcasting and casting rules) to determine the shape, dtype etc. of the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii) Write to disk** We can in fact write the result direct to disk. \n",
    "\n",
    "**EXERCISE**: ``compute`` accepts the same kwargs as the NDArray constructors from the previous tutorial. Write the result to a disk as ``result.b2nd`` and examine the time and memory consumption compared to the case in **i)** above. In principle, no memory is used at all since operands and result are all on disk (why is some memory still used? why is the time taken longer than in **i)**?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "## Check that the result has been written to disk\n",
    "!ls -lh result.b2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iiI) Computing slices** We can also compute just a slice of the result.\n",
    "\n",
    "**EXERCISE**: Look at the documentation of ``compute`` and try to calculate the slice of the result ``slice(2, 200, 25)`` and examine memory consumption and execution time as above. Why is the calculation much faster?\n",
    "Consider what would happen with a plain NumPy calculation - how could you get a slice of the result faster than calculating the whole result and then slicing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:50:50.751445Z",
     "start_time": "2025-08-04T11:50:50.721398Z"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is happening when we call the ``compute`` method? The operands are all NDArray arrays, chunked and stored on disk. When the compute method is called, the expression is executed, chunk-by-chunk, and the result stored, chunk-by-chunk. Hence at any given time, only a small amount of data (a chunk for each operand and the result) must be operated on in memory. The result may be written to memory, chunk-by-chunk, but it is just as easy  (see **ii) Writing to Disk**) to write straight to disk - hence you can operate with very large arrays in a very small memory footprint (a handful of chunks). Moreover, the computation is only performed on the necessary chunks required to give the result slice (see **iii) Computing slices**).\n",
    "\n",
    "**--------------------Exercise 1------------------**\n",
    "\n",
    "Blosc2 automatically selects the chunksize and chunk shape when creating arrays to be ajusted to your machine's cache. However, we can modify the chunksizes of ``a`` and ``b`` to be smaller or larger; can you predict how memory usage might change? What about computation time? The latter is probably more difficult to predict.\n",
    "\n",
    "Extra Credit: Note that we can also specify different compression parameters for the result via the ``cparams`` kwarg of ``compute``.  For example, we can change the codec to `ZLIB`, use the bitshuffle filter, and set the compression level to 9: ``cparams = blosc2.CParams(codec=blosc2.Codec.ZLIB, filters=[blosc2.Filter.BITSHUFFLE], clevel=9)``. What happens to computation time and compression ratio (compare to **i) Computing an expression**) ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chunks are of size: a - {round(a.chunksize/1024**2,2)} MB,  b - {round(b.chunksize/1024**2,2)} MB\")\n",
    "# Now check what the chunkshapes for a and b are and regenerate them with different chunks\n",
    "# Try (100, 5000) for a, (250, 1000) for b\n",
    "\n",
    "#\n",
    "## YOUR CODE HERE ##\n",
    "#\n",
    "\n",
    "# We have to regenerate expression with new operands\n",
    "print(f\"Chunks are now of size: a - {round(a.chunksize/1024**2,2)} MB,  b - {round(b.chunksize/1024**2,2)} MB\")\n",
    "c = a**2 + b**2 + 2 * a * b + 1\n",
    "\n",
    "# Now redo the experiment ii) Writing to disk and see how memory usage and computation time change\n",
    "\n",
    "#\n",
    "## YOUR CODE HERE ##\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reset things back to how they were before\n",
    "a = blosc2.linspace(0, 1, np.prod(shape1), dtype=np.float32, shape=shape1, urlpath=\"a.b2nd\", mode=\"w\")\n",
    "b = blosc2.linspace(1, 2, np.prod(shape2), dtype=np.float64, shape=shape2, urlpath=\"b.b2nd\", mode=\"w\")\n",
    "c = a**2 + b**2 + 2 * a * b + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Returning a NumPy array\n",
    "Now, let's compute the expression and store the result in a NumPy array.  For this, we will use the `__getitem__` method of the ``LAzyExpr`` ``c``; recall that in the previous tutorial `__getitem__` (i.e. ``arr[1:,4]``) also returned a NumPy array (from decompressing a Blosc2 NDArray). The syntax is the same.\n",
    "\n",
    "**EXERCISE**: As we did above, examine the memory consumption, execution time and total space occupied by the result when one returns a NumPy array from a lazy expression - both for a) the full result and b)the slice ``slice(2, 200, 25)``. Check the types and shapes of the resulting arrays. What do you notice about memory, time and storage? Does it all make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:50:50.778316Z",
     "start_time": "2025-08-04T11:50:50.763836Z"
    }
   },
   "outputs": [],
   "source": [
    "# a) compute the full expression c and profile it\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# b) compute a slice of the expression c and profile it\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in either case the result is a NumPy array now.\n",
    "\n",
    "#### Summary\n",
    "Depending on your needs, you can choose to get the result as a NDArray array or as a NumPy array.  The former is more storage efficient, but the latter is more flexible when interacting with other libraries that do not support NDArray arrays, or for reading out data.\n",
    "\n",
    "**Note: Functions**\n",
    "Lazy expressions also support many standard functions (essentially those available in NumPy), such as `sin`, `cos`, `exp`, `log`, etc. as well as reductions like ``sum``, ``mean`` etc.\n",
    "\n",
    "**EXERCISE**: \n",
    "a) Try to write your own lazy expression using the arrays ``a, b`` and some functions in Blosc2 (e.g. ``blosc2.sin``). Examine the type of the result (it should be a ``LazyExpr``). Try to obtain a result slice, first as a Blosc2 NDArray and then as a NumPy array, and check the shapes of the results.\n",
    "\n",
    "b) Apply ``blosc2.sin`` to the lazy expression from part a). What is the type of the result? Now apply a reduction to the lazy expression from part a). What is the type of the result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Write a lazy expression using functions\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# b)\n",
    "# Apply blosc2.sin to lazy expression from a)\n",
    "#YOUR CODE HERE\n",
    "# Apply a reduction to lazy expression from a)\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the result of the reduction expression is not a ``LazyExpr``, but rather a NumPy array (even though no ``__getitem__`` call has been made). This is because reductions in expressions are always executed \"eagerly\" (i.e. on creation of the lazy expression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2) A more practical example\n",
    "\n",
    "Ok, let's put the computation engine through its paces with some proper computations. We shall set up a 3D grid, represented by 3 1D arrays, and exploit broadcasting to reduce memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment Setup ---\n",
    "n_frames = 1000  # Raise this for more frames\n",
    "width, height = np.array((n_frames, n_frames))  # Size of the grid\n",
    "dtype = np.float64  # Data type for the grid\n",
    "\n",
    "# --- Coordinate creation ---\n",
    "x = blosc2.linspace(0, n_frames, n_frames, dtype=dtype)\n",
    "y = blosc2.linspace(-4 * np.pi, 4 * np.pi, width, dtype=dtype)\n",
    "z = blosc2.linspace(-4 * np.pi, 4 * np.pi, height, dtype=dtype)\n",
    "X = blosc2.expand_dims(blosc2.expand_dims(x, 1), 2)  # Shape: (N, 1, 1)\n",
    "Y = blosc2.expand_dims(blosc2.expand_dims(y, 0), 2)  # Shape: (1, N, 1)\n",
    "Z = blosc2.expand_dims(blosc2.expand_dims(z, 0), 0)  # Shape: (1, 1, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define a computation result (in 3D) via a function - later on we shall plot it. We can in fact apply NumPy functions to the blosc2 NDArray arrays and the result will still be a lazyexpr.\n",
    "\n",
    "**EXERCISE**: \n",
    "\n",
    "a) Execute ``expr = genexpr(X, Y, Z)`` and profile the memory consumption and execution time of this execution as above (both should be very low). Check the type of ``expr`` and access its metadata (``shape`` and ``dtype``). \n",
    "\n",
    "b) How much memory (uncompressed) should the result occupy (i.e. how many GB would ``expr[:]`` load into memory?)? You should be able to work this out just from the ``shape`` and ``dtype`` (HINT: What is the ``dtype`` size?) metadata. The accessing of metadata in a) was instantaneous - if this required calculating the final result, do you think it would be as fast, given the size of the result?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate computed data ---\n",
    "def genexpr(a, b, c):\n",
    "    time_factor = a * b * 0.001\n",
    "    R = np.sqrt(b**2 + c**2)\n",
    "    theta = np.arctan2(c, b)\n",
    "    return np.sin(R * 3 - time_factor * 2) * np.cos(theta * 3)\n",
    "\n",
    "#a)\n",
    "# Profile memory usage of expr = genexpr(X, Y, Z)\n",
    "# YOUR CODE HERE\n",
    "# Check type, shape and dtype of expr\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#b) Calculate size of expr result\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate an animation which computes the expression slice-by-slice on-the-fly, using the ``LazyExpr`` ``__getitem__`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(arr):\n",
    "    label = 'NumPy' if isinstance(arr, np.ndarray) else 'Blosc2'\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    a = arr[:,:,0]\n",
    "    im = plt.imshow(a, cmap=\"viridis\")\n",
    "    fig.colorbar(im)\n",
    "    plt.title(\"Animated Plot\")\n",
    "    plt.xlabel(\"X-axis\")\n",
    "    plt.ylabel(\"Y-axis\")\n",
    "    start_time = time.time()\n",
    "    def update(frame_num):\n",
    "        # Evaluate the expression for the current frame on the fly\n",
    "        a = arr[:, :, frame_num]  # <-------------- perform computation\n",
    "        im.set_array(a)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        plt.title(f\"{label}: Frame {frame_num + 1}/{n_frames}, elapsed time = {round(elapsed_time, 2)} s\")\n",
    "        return im,\n",
    "    ani = FuncAnimation(fig, update, frames=n_frames, interval=10, blit=False, repeat=False)\n",
    "    plt.show()\n",
    "    return ani\n",
    "\n",
    "create_video(expr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! So our Blosc2 compute engine works well enough to be useful practically - most of the elapsed time is due to matplotlib rendering.\n",
    "\n",
    "**EXERCISE**: \n",
    "\n",
    "Try to rerun the previous cell but replace the computations with just rendering an empty array - the time should be basically the same. Why might it be advantageous to compute slice-by-slice rather than precompute all frames and then access them?\n",
    "\n",
    "Once you've done all this don't forget to change the``create_video`` function back to the original though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling lazy expressions\n",
    "We now know that the lazy expression machinery is fast enough to be useful. Now we are going to compare memory usage and computation time to NumPy. In order to do that, we should define a helper function which profiles the ``__getitem__`` method of the lazy expression (which returns a NumPy array) and the NumPy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run computation and profile time and memory usage ---\n",
    "def monitor(BLOSC):\n",
    "    m0 = getmem()\n",
    "    t0 = time.time()\n",
    "    expr = genexpr(X, Y, Z)[:] if BLOSC else genexpr(X[:], Y[:], Z[:])\n",
    "    dt = time.time()-t0\n",
    "    if dt > 1e-3:\n",
    "        print(f'Operation took {round(dt, 3)} s')\n",
    "    else:\n",
    "        print(f'Operation took {round(dt * 1000_000, 1)} μs')\n",
    "    print(f'Result occupies {round((getmem()-m0))} MB')\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually do the computation for the lazy expression, for all frames, and see how the memory usage compares to that of the plain NumPy computation.\n",
    "\n",
    "**EXERCISE** \n",
    "\n",
    "Use the ``monitor`` function to profile the Blosc2 lazy expression computation and check the type and nbytes of the result. Delete the result and now use the monitor function to profile the plain NumPy calculation and again check the type and nbytes of the result (both should be the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Profile Blosc2....')\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print('--------\\nProfile NumPy....')\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blosc2, owing to chunking and caching, makes more effective use of machine architecture, so it actually runs faster in practice! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------Exercise 2----------------**\n",
    "\n",
    "a) Run the animation with the result of the NumPy calculation above. Since we precompute all frames, you might expect the animation to run faster. Is this true?\n",
    "You can go back and regenerate the ``expr`` variable to be a ``LazyExpr`` and rerun the Blosc2 animation cell to double check the comparison of the speeds.\n",
    "\n",
    "b) Now try to run the animation but pass a computed Blosc2 array as the ``arr`` parameter (rather than either the uncomputed ``LazyExpr`` object or a NumPy array). What happens now?\n",
    "\n",
    "c) What would happen to memory usage and computation time if, in the ``monitor`` function, we modified the computation to return a Blosc2 NDArray rather than a NumPy array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3) Lazy Expressions and Persistent Reductions\n",
    "\n",
    "Recall that ``blosc2.sum(a)`` returns a computed result, not a lazy expression, which could be undesirable in some cases. Using strings and the ``lazyexpr`` constructor, we can avoid this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expression that sums arrays\n",
    "expression = \"sum(a + b, axis=1)\"\n",
    "# Define the operands for the expression\n",
    "operands = {\"a\": a, \"b\": b}\n",
    "# Create a lazy expression\n",
    "lazy_expression = blosc2.lazyexpr(expression, operands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**---------------EXERCISE 3----------------**\n",
    "\n",
    "a) Check the type of ``lazy_expression`` is indeed a ``LazyExpr``. Try computing the full result and profile the computation. Compare it with the time taken for the eagerly executed version which doesn't use a string.\n",
    "\n",
    "b) Now try computing a slice of ``lazy_expression`` and see if it runs faster than computing the full result. Would the non-string version also be faster? Would the result even be the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#b)\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4) Lazy Expression Operands and Storage\n",
    "\n",
    "We can save lazy expression operands on-disk and then update them - computing any lazy expression in which they appear then gives a new result, since the computation is peformed every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = blosc2.arange(0, 10, urlpath=\"a.b2nd\", mode=\"w\")\n",
    "lexpr = a + 1\n",
    "print(f\"Lazyexpr with old a: {lexpr[:]}\")\n",
    "a = blosc2.arange(10, 20, urlpath=\"a.b2nd\", mode=\"w\")\n",
    "print(f\"Lazyexpr with new a: {lexpr[:]}\")  # This will compute with the new a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-------Exercise 4----------**\n",
    "\n",
    "Now try the same but *without* saving the operands to disk. What happens now? You should see that the behaviour is different. Compare the result of ``id()`` on ``a`` and the values of the ``lexpr.operands`` dict - what do you see? Try saving and reopening ``lexpr`` to disk when the operands are saved on disk (and when they're not) - what happens then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blosc2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m a = \u001b[43mblosc2\u001b[49m.arange(\u001b[32m0\u001b[39m, \u001b[32m10\u001b[39m) \u001b[38;5;66;03m# operand stored in memory\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMemory address of a: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m(a)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m## YOUR CODE  HERE\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'blosc2' is not defined"
     ]
    }
   ],
   "source": [
    "a = blosc2.arange(0, 10) # operand stored in memory\n",
    "print(f\"Memory address of a: {id(a)}\")\n",
    "\n",
    "#\n",
    "## YOUR CODE  HERE\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we have seen how to perform computations with NDArray arrays: how to create lazy expressions, compute them, and save them to disk. Also, we have looked at performing reductions, broadcasting and heavy computations. Lazy expressions allow you to build and compute complex computations from operands that can be in-memory, on-disk or remote (see [`C2Array`](reference/c2array.html)) in a simple and effective way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "blosc2.remove_urlpath(\"a.b2nd\")\n",
    "blosc2.remove_urlpath(\"b.b2nd\")\n",
    "blosc2.remove_urlpath(\"result.b2nd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
