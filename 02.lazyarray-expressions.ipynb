{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Expressions containing NDArray objects\n",
    "\n",
    "Python-Blosc2 implements a powerful way to operate with NDArray arrays and other objects, called \"lazy expressions\".  A lazy expression is a lightweight object which stores a desired computation symbolically, with references to its operands (stored on disk or in memory), but does not execute until data is explicitly requested, e.g. if a slice of the computation result is requested. The lazy expression will then execute, but only on the necessary portion of the data, making it especially efficient, and avoiding large in-memory computations.\n",
    "\n",
    "In this tutorial, we will see how to do such lazy computations, which are especially useful when working with large arrays, owing to this avoidance of costly in-memory temporaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import blosc2\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "%matplotlib ipympl\n",
    "\n",
    "# --- Memory profiler ---\n",
    "def getmem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1) A simple example\n",
    "First, let's create a couple of NDArray arrays. We're going to write them to disk since in principle we are interested in large arrays (so big that they can't fit in memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1 = (500, 10000)\n",
    "shape2 = (10, 500, 10000)\n",
    "a = blosc2.linspace(0, 1, np.prod(shape1), dtype=np.float32, shape=shape1, urlpath=\"a.b2nd\", mode=\"w\")\n",
    "b = blosc2.linspace(1, 2, np.prod(shape2), dtype=np.float64, shape=shape2, urlpath=\"b.b2nd\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a lazy expression, which can be defined via two different APIs (which are exactly equivalent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's create an expression that involves `a` and `b`, called `c`.\n",
    "c = a**2 + b**2 + 2 * a * b + 1\n",
    "print('With direct definition')\n",
    "print(c.info)  # at this stage, the expression has not been computed yet\n",
    "\n",
    "# We can also define a lazyexpr like so\n",
    "c_string = blosc2.lazyexpr('a**2 + b**2 + 2 * a * b + 1')\n",
    "print('With string-based constructor')\n",
    "print(c_string.info)  # at this stage, the expression has not been computed yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, for either API, the type of `c` is a `LazyExpr` object. We'll ignore the string-based constructor for the rest of this tutorial.\n",
    "\n",
    "A ``LazyExpr`` object is a placeholder for the actual computation that will be done when we compute the expression.  This is a very powerful feature because it allows us to build complex expressions without actually computing anything until we really need the result (or a portion of the result).\n",
    "\n",
    "Moreover, we can access the individual metadata of the result (such as ``shape`` and `dtype`) as attributes of the lazy expression ``c`` rapidly, without computing anything. Time how long it takes (using the cell magic ``%time`` or line magic ``%%timeit``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "print(f'Shape of operands: a - {a.shape}, b - {b.shape}')\n",
    "print(f'Shape of result = {c.shape}')\n",
    "print(f'dtype = {c.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, note that the shapes of `a` and `b` are different. However, the shapes are compatible, and so Blosc2 applies **broadcasting** (Ã  la NumPy) efficiently, both to obtain the precomputation metadata (very fast) as well as to perform the computation (slower). \n",
    "\n",
    "Now, let's see all this in action in computation. `LazyExpr` objects follow the [LazyArray interface](../../reference/lazyarray.html), and this provides several ways for performing the computation, depending on the object we want as the desired output.\n",
    "\n",
    "#### 1. Returning a NDArray array\n",
    "**i) Computing an expression** First, let's use the `compute` method. The result will be another NDArray array, which will be compressed and so very storage efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = getmem() #initial memory used\n",
    "t0 = time.time()\n",
    "d = c.compute()\n",
    "print(f\"Computation time {round((time.time() - t0)*1000,1)} ms\")\n",
    "print(f\"Memory used {round(getmem() - m0)} MB\")\n",
    "print(f\"Class: {type(d)}, occupies {round(d.cbytes / 1024 ** 2)} MB. Compression ratio {d.cratio:.2f}x\")\n",
    "del d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that just accessing metadata via e.g. ``c.shape`` took much less time, since it uses the metadata of the operands (plus broadcasting and casting rules) to determine the shape, dtype etc. of the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii) Write to disk** We can in fact write the result direct to disk. \n",
    "\n",
    "**EXERCISE**: ``compute`` accepts the same kwargs (in particular ``urlpath`` and ``mode``) as the NDArray constructors from the previous tutorial. Write the result to a disk as ``result.b2nd`` and examine the time and memory consumption compared to the case in **i)** above. In principle, no memory is used at all since operands and result are all on disk (why is some memory still used? why is the time taken longer than in **i)**?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROFILE (TIME AND MEMORY) THIS LINE\n",
    "d = c.compute(urlpath='result.b2nd', mode ='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d\n",
    "## Check that the result has been written to disk\n",
    "!ls -lh result.b2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iiI) Computing slices** We can also compute just a slice of the result.\n",
    "\n",
    "**EXERCISE**: Look at the documentation of ``compute`` and try to calculate the slice of the result ``slice(2, 200, 25)`` and examine memory consumption and execution time as above. Why is the calculation much faster?\n",
    "Consider what would happen with a plain NumPy calculation - how could you get a slice of the result faster than calculating the whole result and then slicing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROFILE (TIME AND MEMORY) OF SLICING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is happening when we call the ``compute`` method? The operands are all NDArray arrays, chunked and stored on disk. When the compute method is called, the expression is executed, chunk-by-chunk, and the result stored, chunk-by-chunk. Hence at any given time, only a small amount of data (a chunk for each operand and the result) must be operated on in memory. The result may be written to memory, chunk-by-chunk, but it is just as easy  (see **ii) Writing to Disk**) to write straight to disk - hence you can operate with very large arrays in a very small memory footprint (a handful of chunks). Moreover, the computation is only performed on the necessary chunks required to give the result slice (see **iii) Computing slices**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Returning a NumPy array\n",
    "Now, let's compute the expression and store the result in a NumPy array.  For this, we will use the `__getitem__` method of the ``LazyExpr`` ``c``; recall that in the previous tutorial `__getitem__` (i.e. ``arr[1:,4], arr[slice(1,10,1)]``) also returned a NumPy array (from decompressing a Blosc2 NDArray). The syntax is the same.\n",
    "\n",
    "**EXERCISE**: As we did above, examine the memory consumption, execution time and total space occupied by the result when one returns a NumPy array from a lazy expression - both for a) the full result (i.e. ``c[:]``) and b) the slice ``slice(2, 200, 25)``. Check the types and shapes of the resulting arrays. What do you notice about memory, time and storage? Does it all make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) compute the full expression and profile it\n",
    "# YOUR CODE HERE\n",
    "print(f\"Class: {type(d)}, occupies {round(np.prod(d.shape) * d.itemsize / 1024 ** 2)} MB\") # total space occupied\n",
    "\n",
    "# b) compute a slice of the expression and profile it\n",
    "#YOUR CODE HERE\n",
    "print(f\"Class: {type(d)}, occupies {round(np.prod(d.shape) * d.itemsize / 1024 ** 2)} MB\") # total space occupied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in either case the result is a NumPy array now.\n",
    "\n",
    "#### Summary\n",
    "Depending on your needs, you can choose to get the result as a NDArray array or as a NumPy array.  The former is more storage efficient, but the latter is more flexible when interacting with other libraries that do not support NDArray arrays, or for reading out data.\n",
    "\n",
    "**Note: Functions**\n",
    "Lazy expressions also support many standard functions (essentially those available in NumPy), such as `sin`, `cos`, `exp`, `log`, etc. as well as reductions like ``sum``, ``mean`` etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexpr = blosc2.sin(a) + blosc2.exp(b)\n",
    "print(f'lexpr of type : {type(lexpr)} of shape {lexpr.shape} and dtype {lexpr.dtype}')\n",
    "blosc_res = lexpr.compute(item = 5)\n",
    "np_res = lexpr[5]\n",
    "print(f'blosc_res of type {type(blosc_res)}, np_res of type {type(np_res)}')\n",
    "print(f'blosc_res of shape {blosc_res.shape}, np_res of shape {np_res.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2) A more practical example\n",
    "\n",
    "Ok, let's put the computation engine through its paces with some proper computations. We shall set up a 3D grid, represented by 3 1D arrays, and exploit broadcasting to reduce memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment Setup ---\n",
    "n_frames = 100  # Raise this for more frames\n",
    "width, height = np.array((n_frames, n_frames))  # Size of the grid\n",
    "dtype = np.float64  # Data type for the grid\n",
    "\n",
    "# --- Coordinate creation ---\n",
    "x = blosc2.linspace(0, n_frames, n_frames, dtype=dtype)\n",
    "y = blosc2.linspace(-4 * np.pi, 4 * np.pi, width, dtype=dtype)\n",
    "z = blosc2.linspace(-4 * np.pi, 4 * np.pi, height, dtype=dtype)\n",
    "X = blosc2.expand_dims(blosc2.expand_dims(x, 1), 2)  # Shape: (N, 1, 1)\n",
    "Y = blosc2.expand_dims(blosc2.expand_dims(y, 0), 2)  # Shape: (1, N, 1)\n",
    "Z = blosc2.expand_dims(blosc2.expand_dims(z, 0), 0)  # Shape: (1, 1, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define a computation result (in 3D) via a function - later on we shall plot it. We can in fact apply NumPy functions to the blosc2 NDArray arrays and the result will still be a lazyexpr.\n",
    "\n",
    "**EXERCISE**: \n",
    "\n",
    "a) Execute ``expr = genexpr(X, Y, Z)`` and profile the memory consumption and execution time of this execution as above (both should be very low). Check the type of ``expr`` and access its metadata (``shape`` and ``dtype``). \n",
    "\n",
    "b) How much memory (uncompressed) should the result occupy (i.e. how many GB would ``expr[:]`` load into memory?)? If ``expr`` were an NDArray, one could do ``expr.nbytes`` but since it is a ``LazyExpr``, we cannot do this. Instead, you should be able to work this out just from the ``shape`` and ``dtype`` (HINT: Use the ``dtype.itemsize`` attribute?) metadata. The accessing of metadata in a) was instantaneous - if this required calculating the final result, do you think it would be as fast, given the size of the result?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate computed data ---\n",
    "def genexpr(a, b, c):\n",
    "    time_factor = a * b * 0.001\n",
    "    R = np.sqrt(b**2 + c**2)\n",
    "    theta = np.arctan2(c, b)\n",
    "    return np.sin(R * 3 - time_factor * 2) * np.cos(theta * 3)\n",
    "\n",
    "#a)\n",
    "# Profile memory usage of expr = genexpr(X, Y, Z)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Check type, shape and dtype of expr\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#b) Calculate size of expr result\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate an animation which computes the expression slice-by-slice on-the-fly, using the ``LazyExpr`` ``__getitem__`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(arr):\n",
    "    label = 'NumPy' if isinstance(arr, np.ndarray) else 'Blosc2'\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    a = arr[:,:,0]\n",
    "    im = plt.imshow(a, cmap=\"viridis\")\n",
    "    fig.colorbar(im)\n",
    "    plt.title(\"Animated Plot\")\n",
    "    plt.xlabel(\"X-axis\")\n",
    "    plt.ylabel(\"Y-axis\")\n",
    "    start_time = time.time()\n",
    "    def update(frame_num):\n",
    "        # Evaluate the expression for the current frame on the fly\n",
    "        a = arr[:, :, frame_num]  # <-------------- perform computation\n",
    "        im.set_array(a)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        plt.title(f\"{label}: Frame {frame_num + 1}/{n_frames}, elapsed time = {round(elapsed_time, 2)} s\")\n",
    "        return im,\n",
    "    ani = FuncAnimation(fig, update, frames=n_frames, interval=10, blit=False, repeat=False)\n",
    "    plt.show()\n",
    "    return ani\n",
    "\n",
    "create_video(expr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! So our Blosc2 compute engine works well enough to be useful practically - most of the elapsed time is due to matplotlib rendering.\n",
    "\n",
    "**EXERCISE**: \n",
    "\n",
    "Try to rerun the previous cell but replace the computations with just rendering an empty array - the time should be basically the same. Why might it be advantageous to compute slice-by-slice rather than precompute all frames and then access them?\n",
    "\n",
    "Once you've done all this don't forget to change the``create_video`` function back to the original though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling lazy expressions\n",
    "We now know that the lazy expression machinery is fast enough to be useful. Now we are going to compare memory usage and computation time to NumPy. In order to do that, we should define a helper function which profiles the ``__getitem__`` method of the lazy expression (which returns a NumPy array) and the NumPy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run computation and profile time and memory usage ---\n",
    "def monitor(BLOSC=True):\n",
    "    m0 = getmem()\n",
    "    t0 = time.time()\n",
    "    expr = genexpr(X, Y, Z)[:] if BLOSC else genexpr(X[:], Y[:], Z[:])\n",
    "    dt = time.time()-t0\n",
    "    if dt > 1e-3:\n",
    "        print(f'Operation took {round(dt, 3)} s')\n",
    "    else:\n",
    "        print(f'Operation took {round(dt * 1000_000, 1)} Î¼s')\n",
    "    print(f'Result occupies {round((getmem()-m0))} MB')\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually do the computation for the lazy expression, for all frames, and see how the memory usage compares to that of the plain NumPy computation.\n",
    "\n",
    "**EXERCISE** \n",
    "\n",
    "a) Use the ``monitor`` function to profile the Blosc2 lazy expression computation (``genexpr(X, Y, Z)[:]``) and check the type and nbytes of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Profile Blosc2....')\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Delete the result and now use the ``monitor`` function to profile the plain NumPy calculation (``genexpr(X[:], Y[:], Z[:])``) and again check the type and nbytes of the result (both should be the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result\n",
    "print('--------\\nProfile NumPy....')\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blosc2, owing to chunking and caching, makes more effective use of machine architecture, so it actually runs faster in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we have seen how to perform computations with NDArray arrays: how to create lazy expressions, compute them, and save them to disk. Also, we have looked at performing reductions, broadcasting and heavy computations. Lazy expressions allow you to build and compute complex computations from operands that can be in-memory, on-disk or remote (see [`C2Array`](reference/c2array.html)) in a simple and effective way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "blosc2.remove_urlpath(\"a.b2nd\")\n",
    "blosc2.remove_urlpath(\"b.b2nd\")\n",
    "blosc2.remove_urlpath(\"result.b2nd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
