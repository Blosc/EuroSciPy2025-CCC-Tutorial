{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tutorial 3: Working with remote datasets\n",
    "In this tutorial we will see how to work with remote datasets using Blosc2 and Caterva2, a library that allows you to manage large remote datasets, providing a client-server architecture. Caterva2 is built on top of Blosc2, so it can handle large datasets efficiently using all the tools and tricks you've learned in the previous tutorials."
   ],
   "id": "fff2e92d087c0aeb"
  },
  {
   "id": "2f2e41b4-44ec-458b-9949-b73ea1ee1350",
   "cell_type": "code",
   "source": [
    "import math\n",
    "import blosc2\n",
    "import caterva2 as cat2\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# --- Memory profiler ---\n",
    "def getmem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we need to connect to the remote server - we have a demo running at `https://cat2.cloud/demo` that's good to get you started quickly.",
   "id": "66837447f20b7ebf"
  },
  {
   "id": "d4305fc6-675e-4e11-8152-f23e6ad9b648",
   "cell_type": "code",
   "source": [
    "urlbase = \"https://cat2.cloud/demo\"\n",
    "root = \"@public\"\n",
    "dataset1 = \"examples/cubeA.b2nd\"\n",
    "dataset2 = \"examples/cubeB.b2nd\""
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "a98d0042-6193-45ce-8b64-3bdd604321bf",
   "cell_type": "markdown",
   "source": [
    "### Blosc2 approach: simple, but allows slicing of remote datasets\n",
    "\n",
    "Noe let's access the remote dataset using Blosc2, which is possible using essentially the same interface as for datasets stored on disk - the only difference is that we need to wrap the urlpath as a `blosc2.URLPath` object, to indicate that we are accessing a remote dataset.\n"
   ],
   "metadata": {}
  },
  {
   "id": "34eb55a6-ed02-4c89-87ab-d5a38ff6a91c",
   "cell_type": "code",
   "source": [
    "urlpath = blosc2.URLPath(f\"{root}/{dataset1}\", urlbase)\n",
    "m0 = getmem()\n",
    "t0 = time.time()\n",
    "blosc_arr1 = blosc2.open(urlpath, mode=\"r\")\n",
    "print(\"Time to open remote dataset 1:\", time.time() - t0, 's')\n",
    "print(\"Memory usage after opening remote dataset 1:\", getmem() - m0, \"MB\")\n",
    "\n",
    "urlpath = blosc2.URLPath(f\"{root}/{dataset2}\", urlbase)\n",
    "m0 = getmem()\n",
    "t0 = time.time()\n",
    "blosc_arr2 = blosc2.open(urlpath, mode=\"r\")\n",
    "print(\"Time to open remote dataset 2:\", time.time() - t0, 's')\n",
    "print(\"Memory usage after opening remote dataset 2:\", getmem() - m0, \"MB\")"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When we request data from the remote server, it will be sent chunk-by-chunk, compressed, which increases transfer speeds significantly (by the same factor as the compression ratio), which in this case is:",
   "id": "f9e957cf6e0b0641"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'cratio of arr1: {round(blosc_arr1.meta[\"schunk\"][\"cratio\"],2)}x')\n",
    "print(f'cratio of arr2: {round(blosc_arr2.meta[\"schunk\"][\"cratio\"],2)}x')"
   ],
   "id": "1a1f9800d94e68bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "a) Print out the shapes of the datasets and calculate their size (in MB). You will find that ``arr.schunk.nbytes`` does not work, since the variable is not a Blosc2 NDArray. Instead find the correct entry in the ``arr.meta[\"schunk\"]`` dict. What class is are the arrays instances of? Why is it that opening the remote dataset uses no memory when the dataset is so large?\n",
    "\n",
    "b) You should find that the remote access to the dataset has returned a ``C2Array`` object, which is a (memory-light) pointer to the remote dataset. Try and get a slice of ``blosc_arr2`` `blosc_arr2[1, :1000, :1000]`, and print out its type. Profile the time and memory consumption of this operation, and compare it to the time and memory consumption of opening the remote dataset.\n",
    "\n",
    "c) Recalling the string-based lazy expression constructor from the previous tutorial, we can define a lazy expression which calculates some complicated expression. Execute it via ``[:]``, returning a NumPy array. Profile the time and memory usage for the operation. You can use ``%memit`` or ``getmem()`` as you prefer. You can also check what happens when you only compute a small slice of the result (is it any faster? how much memory is used?)."
   ],
   "id": "3ca5c4e45fe41aab"
  },
  {
   "id": "edeb5963-ba4c-4170-90a6-08980834a47f",
   "cell_type": "code",
   "source": [
    "# a) Calculate the shape and nbytes of the datasets, and print out the type of blosc_arr1\n",
    "#\n",
    "## YOUR CODE HERE\n",
    "#\n",
    "\n",
    "# b) Get a slice of blosc_arr1, print out its type, and profile time and memory consumption\n",
    "m0 = getmem()\n",
    "t0 = time.time()\n",
    "#\n",
    "##YOUR CODE HERE\n",
    "#\n",
    "print(\"Time to open slice of remote dataset 1:\", time.time() - t0, 's')\n",
    "print(\"Memory usage after opening slice of remote dataset 1:\", getmem() - m0, \"MB\")\n",
    "\n",
    "\n",
    "# c) Define a simple lazy expression using blosc_arr1, blosc_arr2 and compute it\n",
    "expr = 'mean(sin(arr1) + 2 * exp(arr2 + 1), axis = 1)'\n",
    "lexpr = blosc2.lazyexpr(expr, operands={'arr1':blosc_arr1, 'arr2':blosc_arr2})\n",
    "#\n",
    "## YOUR CODE HERE\n",
    "#\n",
    "del result"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "9da4112c-d607-464e-adbc-6bb1664a20d9",
   "cell_type": "markdown",
   "source": [
    "### Caterva2 approach: more flexible, allowing remote management in the server\n",
    "\n",
    "Using blosc2 we thus can access remote datasets and download necessary slices. However, in order to do computations, we must download data to the local machine and compute with it, which could be excessively computationally demanding. Moreover, we cannot manage do file management on the server side (move, delete, copy datasets, etc.).\n",
    "\n",
    "These problems are solved by Caterva2, which allows us to work with remote datasets in a more flexible way, doing as much as possible on the server side, and only downloading the data we really want to consult. You can also perform all sorts of file management operations on the server side - see the [Caterva2 documentation](https://ironarray.io/caterva2-doc/tutorials/API.html).\n",
    "\n",
    "First we set up a connection from the client (our local machine) to the server, and define a pointer to the root where our desired dataset is stored. The root is a special directory that contains all the datasets we want to work with, and it is defined by the `@` symbol followed by the name of the root (in this case, `@public`). We'll then time the process of opening the remote dataset, and check the memory usage before and after opening it."
   ],
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = cat2.Client(urlbase)\n",
    "myroot = client.get(root)"
   ],
   "id": "7088b9fb96b83d67",
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "36746c32-6669-44ea-818e-9b08d6638bc6",
   "cell_type": "code",
   "source": [
    "m0 = getmem()\n",
    "t0 = time.time()\n",
    "cat2_arr1 = myroot[dataset1]\n",
    "print(\"Time to open remote dataset 1:\", time.time() - t0, 's')\n",
    "print(\"Memory usage after opening remote dataset 1:\", getmem() - m0, \"MB\")\n",
    "\n",
    "m0 = getmem()\n",
    "t0 = time.time()\n",
    "cat2_arr2 = myroot[dataset2]\n",
    "print(\"Time to open remote dataset 2:\", time.time() - t0, 's')\n",
    "print(\"Memory usage after opening remote dataset 2:\", getmem() - m0, \"MB\")"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As before, both time and memory usage are very low, since again we are only creating a pointer to the remote dataset, and not downloading it to the local machine.\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "a) Print out the shape of the datasets and calculate their size (in MB). What class is ``cat2_arr1`` an instance of?\n",
    "\n",
    "b) You should find that the remote access to the dataset has returned a ``caterva2.client.Dataset`` object. Try and get a slice of the dataset, e.g. `cat2_arr1[500:502, 302, 900:905]`, and print out its type. Profile the time and memory consumption of this operation, and compare it to the time and memory consumption of accessing the remote dataset using blosc2 that we saw above.\n"
   ],
   "id": "2f1f643b08457287"
  },
  {
   "id": "62ee97b1-5d36-4ada-b6cd-abb3c017a817",
   "cell_type": "code",
   "source": [
    "# a) Calculate the shape and nbytes of the dataset, and print out the type of cat2_ds\n",
    "#\n",
    "## YOUR CODE HERE\n",
    "#\n",
    "\n",
    "# b) Get a slice of cat2_ds, print out its type, and profile time and memory consumption\n",
    "#\n",
    "## YOUR CODE HERE\n",
    "#"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Now we are going to try and compute the same lazy expression as before, but executed server-side and only downloading the result locally. We thus take advantage of the greater computational resources of the server to perform the computation and execute where the datasets already are, thus saving on transfer time. Now let's see how much time we can save in total!\n",
    "\n",
    "In order to have write-access to the server, we have to authenticate ourselves with the server. This is done by passing a tuple with the username and password to the ``Client`` constructor. If you don't have an account, you can create one at https://cat2.cloud/demo/login.\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "a) Modify the code below to authenticate yourself and then use the ``lazyexpr`` constructor of the ``Client`` class to save a lazy expression on the server which refers to the remote dataset.\n"
   ],
   "id": "1503402defb68449"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# a) Define a simple lazy expression using cat2_ds\n",
    "client = cat2.Client(urlbase, (\"user@example.com\", \"foobar12\"))  # Replace with your credentials\n",
    "client.timeout = 60  # Set a timeout for the operations\n",
    "lexpr_path = client.lazyexpr('my_lazyexpr', expression=expr, operands={'arr1': cat2_arr1.path, 'arr2': cat2_arr2.path}) # Replace 'YOUR_EXPRESSION' with a valid expression"
   ],
   "id": "1526409e38bfa04f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "b) Inspect the type of `lexpr`. You will see that we cannot simply compute it. Instead, we need to use the ``Client.get`` method to get a local pointer to the remote lazy expression.\n",
    "Do this, and access metadata of the result (what type is it?), such as its shape and dtype.\n",
    "\n",
    "c) Finally we can compute and return the lazy expression using the ``[:]`` method of the local pointer to the remote lazy expression. Profile the time and memory usage for this operation, and compare it to the time and memory usage of computing the lazy expression using blosc2 that we saw above. You can also check what happens when you only compute a small slice of the result."
   ],
   "id": "e265826f8ded1f3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# b) Get a local pointer to the remote lazy expression and access its metadata\n",
    "#\n",
    "## YOUR CODE HERE\n",
    "#\n",
    "\n",
    "# c) Compute the lazy expression and profile time and memory usage\n",
    "#\n",
    "## YOUR CODE HERE\n",
    "#"
   ],
   "id": "5b83628934c2b48c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## BONUS: Setting up your own server\n",
    "\n",
    "In case you have your own server running that you would like to connect to and run Caterva2 on, you can do so by following these steps.\n",
    "1) In a command line terminal, execute ``CATERVA2_SECRET=c2sikrit cat2sub``. Check that the server is running at `http://localhost:8000`.\n",
    "2) In a separate terminal, execute ``cat2adduser user@example.com foobar11`` to create a new user on the server.\n",
    "\n",
    "You may then return to this Jupyter notebook and use the code below to connect to your server.\n",
    "Explore the Caterva2 documentation for the ``Client`` class and try and upload a file to the server (see [this tutorial](https://ironarray.io/caterva2-doc/tutorials/API.html) if you get stuck."
   ],
   "id": "96b3f5917ad55f2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = cat2.Client(\"http://localhost:8000\", (\"user@example.com\", \"foobar11\"))\n",
    "#\n",
    "## YOUR CODE HERE\n",
    "#"
   ],
   "id": "ec30bd2e7c2ab217",
   "outputs": [],
   "execution_count": null
  }
 ]
}
